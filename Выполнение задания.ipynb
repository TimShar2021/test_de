{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b7bbac0-c14c-46f7-b8c5-16241b9b5ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.configdefaults): g++ not detected!  PyTensor will be unable to compile C-implementations and will default to Python. Performance may be severely degraded. To remove this warning, set PyTensor flags cxx to an empty string.\n",
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "from multiprocessing import Pool\n",
    "import gc\n",
    "from dask.distributed import Client\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker \n",
    "from collections import Counter\n",
    "from dask_ml.model_selection import train_test_split\n",
    "import statsmodels.stats.api as sms\n",
    "from scipy import stats as st\n",
    "import pymc as pm\n",
    "import requests \n",
    "from urllib.parse import urlencode "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35bc8a5-bfba-4964-875d-34ffa4094b49",
   "metadata": {},
   "source": [
    "# Считывание и процессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da6787dd-e759-4522-bfb7-5a1cc01bc5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# используем api \n",
    "base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?' \n",
    "public_key = 'https://disk.yandex.ru/d/iGDvY2cr0w8ZJA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "920037c0-2417-4b9e-b44d-fd02dc99ce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем url\n",
    "final_url = base_url + urlencode(dict(public_key=public_key)) \n",
    "response = requests.get(final_url) \n",
    "download_url = response.json()['href'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c399271-6c0a-423a-a29c-5fc9af135138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл CSV успешно прочитан.\n",
      "   id             name    amount            date_time approved  \\\n",
      "0   1    Carl Campbell  342525.0  2021-09-16 13:47:00     True   \n",
      "1   2        Ann Noble  247819.0  2019-07-30 22:31:22     True   \n",
      "2   3  Jennifer Cooper  878271.0  2022-06-10 09:48:36     True   \n",
      "3   4     Tracy Murphy  495827.0  2022-07-03 02:30:00    False   \n",
      "4   5   Zachary Morton  559102.0  2020-11-26 00:21:37     True   \n",
      "\n",
      "                                          comment  \n",
      "0               Throughout he weight stand least.  \n",
      "1                       Theory live office great.  \n",
      "2     Plan forward decision tonight officer such.  \n",
      "3  Out ago daughter movement improve table spend.  \n",
      "4               But book cold like popular spend.  \n"
     ]
    }
   ],
   "source": [
    "client = Client(memory_limit='4GB')\n",
    "client\n",
    "\n",
    "# Определение типов данных для столбцов\n",
    "dtypes = {\n",
    "    'id': 'int64',\n",
    "    'name': 'object',\n",
    "    'amount': 'float64',\n",
    "    'date_time': 'object',  \n",
    "    'approved': 'object',  \n",
    "    'comment': 'object'\n",
    "}\n",
    "\n",
    "# чтение файла CSV в Dask DataFrame с указанными типами данных\n",
    "try:\n",
    "    ddf = dd.read_csv(download_url, dtype=dtypes, na_values = [''])\n",
    "    print(\"Файл CSV успешно прочитан.\")\n",
    "    print(ddf.head())\n",
    "    \n",
    "    # удаление пустых/ na строк  -- нам можно оставить пустые строки только в комментариях \n",
    "    # в остальных столбцах их лучше убрать \n",
    "    \n",
    "    ddf = ddf.dropna(how='all')\n",
    "    ddf = ddf.dropna(subset=['id','name','amount','date_time','approved']).reset_index(drop=True)\n",
    "\n",
    "    # Переведем approved в правильный тип\n",
    "    ddf['approved'] = ddf['approved'].astype('bool')\n",
    "\n",
    "    \n",
    "    # удаление дублей\n",
    "    ddf = ddf.drop_duplicates(split_out=ddf.npartitions)\n",
    "\n",
    "    \n",
    "    # преобразование столбца date_time в datetime формат\n",
    "    ddf['date_time'] = dd.to_datetime(ddf['date_time'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # добавление столбца \n",
    "    ddf['hour'] = ddf['date_time'].apply(lambda x:x.hour, meta=('date_time', 'int64'))\n",
    "\n",
    "    # удалить записи в промежутке от 1 до 3 часов ночи\n",
    "    ddf = ddf[(ddf['hour']>3)|(ddf['hour']<1)]\n",
    "    \n",
    "    # сохранение результата \n",
    "    ddf.to_parquet('work_direct_1')\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при обработке файла: {e}\")\n",
    "\n",
    "# Закрытие клиент\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46e7baf-93d7-4d97-855b-27957481b8b9",
   "metadata": {},
   "source": [
    "# Расчет метрик\n",
    "Агрегация по времени, для каждого часа рассчитать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d309ee-5012-4065-bba1-59e4f2272aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(memory_limit='4GB')\n",
    "client\n",
    "\n",
    "# чтение файлов parquet в Dask DataFrame \n",
    "try:\n",
    "    df = dd.read_parquet('work_direct_1')\n",
    "    print(\"Файлы успешно загружены.\")\n",
    "    \n",
    "    # Агрегация по времени, для каждого часа рассчитать\n",
    "    # кол-во уникальных string\n",
    "    name_n = df.groupby(['hour']).name.nunique(split_out=df.npartitions).to_frame().reset_index()\n",
    "    name_n.columns = ['hour', 'name_nuniq']\n",
    "    comment_n = df.groupby(['hour']).comment.nunique(split_out=df.npartitions).to_frame().reset_index()\n",
    "    comment_n.columns = ['hour', 'comment_nuniq']\n",
    "    \n",
    "    # среднее и медиану для numeric\n",
    "    num_mean = df.groupby(['hour']).amount.mean(split_out=df.npartitions).to_frame().reset_index()\n",
    "    num_mean.columns = ['hour', 'amount_mean']\n",
    "    num_median = df.groupby(['hour']).amount.median(split_out=df.npartitions).to_frame().reset_index()\n",
    "    num_median.columns = ['hour', 'amount_median']\n",
    "\n",
    "    part_1 = name_n.merge(comment_n, on = 'hour', how = 'outer')\n",
    "    part_2 = part_1.merge(num_mean, on = 'hour', how = 'outer') \n",
    "    metrics = part_2.merge(num_median, on = 'hour', how = 'outer').compute()\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при обработке файла: {e}\")\n",
    "\n",
    "# Закрытие клиент\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60f0f4c-0899-41f3-a0cc-b9f99400de5c",
   "metadata": {},
   "source": [
    "SQL запрос для выполнения подобных расчетов напрямую в базе данных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a459af-6219-4c65-a9bb-b4e0dc870dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql\n",
    "#\n",
    "# SELECT EXTRACT(HOUR FROM CAST(b.date_time AS date)) AS HOUR,\n",
    "#        COUNT(DISTINCT(b.name)) AS count_uniq_name,\n",
    "#\t     COUNT(DISTINCT(b.comment)) AS count_uniq_comment,\n",
    "#        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY b.amount) OVER \n",
    "#        (PARTITION  BY EXTRACT(HOUR FROM CAST(b.date_time AS date))) AS median_amount,\n",
    "#        AVG(amount) AS mean_amount\n",
    "# FROM baza AS b\n",
    "# GROUP BY EXTRACT(HOUR FROM CAST(b.date_time AS date));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96a5abc-b274-480c-b318-ade618ba8451",
   "metadata": {},
   "source": [
    "# Мерж с метриками\n",
    "К каждой строке в исходном датасете примержить метрики ближайшего часа рассчитанные в предыдущем шаге"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a74226-3d8b-42fd-bf01-3eb31a869dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(memory_limit='4GB')\n",
    "client\n",
    "\n",
    "try:\n",
    "    \n",
    "    # К каждой строке в исходном датасете примержить метрики \n",
    "    # ближайшего часа рассчитанные в предыдущем шаге\n",
    "    dfm = df.merge(metrics, on='hour', how = 'left')\n",
    "    dfm.to_parquet('work_direct_2')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при обработке файла: {e}\")\n",
    "\n",
    "# Закрытие клиент\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d721ec41-089d-4d39-822b-00b685a1a8ee",
   "metadata": {},
   "source": [
    "# Аналитические метрики\n",
    "Для колонки numeric по полному датасету построить"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dc8df5-cdd0-439e-9914-396aa16df55f",
   "metadata": {},
   "source": [
    "• Гистограмму"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693406c4-0b84-4bd4-8743-bf2afb8470b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(memory_limit='4GB')\n",
    "client\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "plt.hist(df['amount'].compute(), bins=1000)\n",
    "plt.ylim(84000,91000)\n",
    "xlabels = ['{:,.2f}'.format(x) + 'K' for x in ax.get_xticks()/1000]\n",
    "ax.set_xticklabels(xlabels)\n",
    "plt.title('Гистограмма по полю amount')\n",
    "plt.xlabel('Значения')\n",
    "plt.ylabel('Количество')\n",
    "plt.show()\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add69ee8-f377-4e64-9cd2-abf3685efc01",
   "metadata": {},
   "source": [
    "Нам известно, что для генеральной совокупности, которой в данном случае является наш датасет, 95% всех выборочных средних разместятся вокруг настоящего среднего ГС в диапазоне ± 1,96 стандартного отклонения.\n",
    "Поэтому легко найти среднее и стандартное отклонение, и на основе них рассчитать 95% доверительный интревал."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d80f213-2e1f-44db-8124-d8b9df966013",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(memory_limit='4GB')\n",
    "client\n",
    "\n",
    "std_deviation = df['amount'].std().compute()\n",
    "ma = df['amount'].mean().compute()\n",
    "min_board = ma - (1.96 * std_deviation)\n",
    "max_board = ma + (1.96 * std_deviation)\n",
    "di = min_board, max_board \n",
    "\n",
    "client.close()\n",
    "\n",
    "print(f'95% доверительный интервал: {di}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14424524-f522-4698-9ef7-ff5cac1a79ed",
   "metadata": {},
   "source": [
    "# Визуализация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d365f23c-bb71-41b9-82f7-67dcb8db4683",
   "metadata": {},
   "source": [
    "Отрисовать график среднего значения numeric колонки (y) по месяцам (x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8cf8c1-74fc-4545-aa65-4e49837afef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(memory_limit='4GB')\n",
    "client\n",
    "\n",
    "df['month'] = df['date_time'].apply(lambda x:x.month, meta=('date_time', 'int64'))\n",
    "gm = df.groupby('month').amount.mean().to_frame().reset_index().compute()\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be388873-f7da-4a62-917f-467ed23e7fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_map = {1: 'Январь', 2: 'Февраль',\n",
    "             3: 'Март', 4:  'Апрель', 5: 'Май',\n",
    "             6: 'Июнь', 7: 'Июль', 8: 'Август', 9: 'Сентябрь',\n",
    "            10: 'Октябрь',11: 'Ноябрь',12: 'Декабрь'}\n",
    "\n",
    "gm['month'] = gm['month'].map(month_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936f4b0f-aae2-4c52-8b71-f020370b84ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize =(12, 7))\n",
    " \n",
    "# Горизонтальный Bar Plot\n",
    "\n",
    "plt.bar(gm['month'], gm['amount'], color = '#62639B')\n",
    "plt.ylim(490000,505000) \n",
    "\n",
    "# Рисуем \n",
    "\n",
    "plt.title('Распределение среднего значения \"amount\" по месяцам',fontsize=18)\n",
    "plt.ylabel('Значение \"amount\"')\n",
    "plt.xlabel('Месяц')\n",
    "plt.legend(['amount'])\n",
    "ax = plt.gca()\n",
    "ax.grid(True,color ='#d7d7d7')\n",
    "ax.set_facecolor('#F8F8FF')\n",
    "ax.set_xticks(gm['month'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c313368-bf44-4918-818f-64d19ecf8f1a",
   "metadata": {},
   "source": [
    "Heatmap по частотности символов в колонке string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f10dc4d-fedd-4656-8a7c-f30a3ccf4abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(memory_limit='4GB')\n",
    "client\n",
    "\n",
    "# Функция для подсчета частот символов в одной партиции\n",
    "def count_characters(partition):\n",
    "    # Удаление пропущенных значений\n",
    "    partition = partition.dropna()\n",
    "    all_strings = ''.join(partition['comment'])\n",
    "    \n",
    "    frequency_dict = {}\n",
    "    for char in all_strings:\n",
    "        if char in frequency_dict:\n",
    "            frequency_dict[char] += 1\n",
    "        else:\n",
    "            frequency_dict[char] = 1\n",
    "    return pd.DataFrame(list(frequency_dict.items()), columns=['Символ', 'Частотность'])\n",
    "\n",
    "# Применение функции ко всему DataFrame\n",
    "char_counts = df.map_partitions(count_characters).compute()\n",
    "\n",
    "# Объединение результатов подсчета из всех партиций\n",
    "total_counts = char_counts.groupby('Символ')['Частотность'].sum().reset_index()\n",
    "\n",
    "# Конвертация в DataFrame для heatmap\n",
    "freq_df = total_counts.sort_values(by='Частотность', ascending=False)\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85465ef-2632-48e5-8c9e-0e4e601c9406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Подготовка данных для heatmap\n",
    "characters = freq_df['Символ'].values\n",
    "frequencies = freq_df['Частотность'].values\n",
    "\n",
    "# Создание heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "heatmap = ax.imshow(frequencies.reshape(-1, 1), cmap='viridis', aspect='auto')\n",
    "\n",
    "# Настройка осей\n",
    "ax.set_yticks(np.arange(len(characters)))\n",
    "ax.set_yticklabels(characters)\n",
    "ax.set_xticks([])\n",
    "\n",
    "# Добавление цветовой шкалы\n",
    "cbar = ax.figure.colorbar(heatmap, ax=ax)\n",
    "cbar.ax.set_ylabel('Частотность', rotation=-90, va=\"bottom\")\n",
    "\n",
    "# Добавление подписей\n",
    "for i in range(len(characters)):\n",
    "    text = ax.text(0, i, frequencies[i], ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "plt.title('Частотность символов Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d11c45-762d-4a16-8888-a176902eb90e",
   "metadata": {},
   "source": [
    "# Доп. задание\n",
    "    1. Случайно поделить датасет на 3 части - в одной 25% записей, во второй 25% и 50% в третьей.\n",
    "    2. Проверить на статистическую значимость различий для среднего по колонке numeric\n",
    "    3. Оценить силу эффекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4314574b-9d51-4dd5-b5b7-77f7ce8db943",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_parquet('work_direct_1')\n",
    "print(\"Файлы успешно загружены.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa38db07-61a2-48d2-a285-eb2043ec9679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делим датасет на 50% и 50%\n",
    "df_50, df_temp = train_test_split(df, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "# Делим временный датасет на 25% и 25%\n",
    "df_25_1, df_25_2 = train_test_split(df_temp, test_size=0.5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0533d8f-ce53-44f2-a0d5-f64fb2fb4e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(memory_limit='4GB')\n",
    "client\n",
    "\n",
    "s_1 = df_25_1['amount'].compute()\n",
    "s_2 = df_25_2['amount'].compute()\n",
    "s_3 = df_50['amount'].compute()\n",
    "\n",
    "\n",
    "client.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d936e5-9944-4fe4-86c8-77c4a46a4439",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05 # уровень статистической значимости\n",
    "\n",
    "print('Для df_25_1 и df_25_2:')\n",
    "\n",
    "results = st.ttest_ind(s_1, s_2)\n",
    "\n",
    "print('p-значение:', results.pvalue)\n",
    "\n",
    "if results.pvalue < alpha:\n",
    "    print('Отличия статистически значимы')\n",
    "else:\n",
    "    print('Отличия статистически не значимы')\n",
    "\n",
    "print('Для df_25_1 и df_50:')\n",
    "\n",
    "results_1 = st.ttest_ind(s_1, s_3)\n",
    "\n",
    "print('p-значение:', results_1.pvalue)\n",
    "\n",
    "if results.pvalue < alpha:\n",
    "    print('Отличия статистически значимы')\n",
    "else:\n",
    "    print('Отличия статистически не значимы')\n",
    "\n",
    "print('Для df_25_2 и df_50:')\n",
    "\n",
    "results_1 = st.ttest_ind(s_2, s_3)\n",
    "\n",
    "print('p-значение:', results_1.pvalue)\n",
    "\n",
    "if results.pvalue < alpha:\n",
    "    print('Отличия статистически значимы')\n",
    "else:\n",
    "    print('Отличия статистически не значимы')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df861b5c-1422-4382-8b69-a40f87107a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(memory_limit='4GB')\n",
    "client\n",
    "\n",
    "size_1 = df_25_1.shape[0].compute()\n",
    "size_2 = df_50.shape[0].compute()\n",
    "\n",
    "sigma_1 = df_25_1['amount'].std().compute()\n",
    "sigma_2 = df_50['amount'].std().compute()\n",
    "\n",
    "\n",
    "client.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d432d6d4-6ae5-4a5f-93a8-7e9516849618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# расчет мощности\n",
    "effect_size = (s_1.mean() - s_2.mean()) / sigma_1\n",
    "power_analysis = sms.TTestPower()\n",
    "power = power_analysis.solve_power(effect_size=effect_size, nobs=size_1, alpha=alpha, alternative='two-sided')\n",
    "\n",
    "print(f\"Мощность теста для одинаковых выборок: {power:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b9d6a6-baf2-41c4-a0b9-03181ee82d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_size_2 = (s_1.mean() - s_3.mean())/np.sqrt(((size_1- 1) * sigma_1**2 + (size_2 - 1) * sigma_2**2) / (size_1 + size_2 - 2))\n",
    "\n",
    "analysis = sms.TTestIndPower()\n",
    "power = analysis.solve_power(effect_size=effect_size_2, nobs1=size_1, alpha=alpha, ratio=size_2/size_1, alternative='two-sided')\n",
    "\n",
    "print(f'Мощность теста для маленькой и большой выборки: {power:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
